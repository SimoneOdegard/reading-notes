# Read 41

## Ethics in Tech

### Ethics in the workplace

[The code I'm still ashamed of](https://www.freecodecamp.org/news/the-code-im-still-ashamed-of-e4c021dff55e/)

The developer in the article had to create a quiz that always recommended the client's drug. There was a young girl who killed herself after taking the drug as a side effect was severe depression and suicidal thoughts. The developer decided to resign from his position and still thinks about how he wrote that code. It seems very unethical to write something like a quiz that even recommends a drug you should take. We are not doctors. We shouldn't be telling people that a drug is good for them when we don't know their medical history. As someone who takes medicine on a daily basis, it seems very wrong to recommend a drug to someone when you're not a licensed professional.

### Ethics in Technology

[Morality, ethics of a self-driving car: Who decides who lives, dies?](https://www.freep.com/story/money/cars/2017/11/21/self-driving-cars-ethics/804805001/)

What happens if you're in a self driving vehicle and someone drives poorly about to cause an accident? Who dies when the car is forced into a no-win situation? How is it ethical to prioritize one life over another? There has been talks that to avoid accidents, it would go for the smaller thing. But what if the smaller thing is a child? Developers are making ethical judgment calls all the time to determine what objects the car will see and how it will react. This article opened my eyes to self driving cars. I didn't really think about what would happen when another driver almost causes an accident, or a child runs into the road, or even if there's debris in the road. It seems like it would make things really difficult to leave the decisions up to legislators, courts, and regulators. How do we know that they would be able to make the best decision? How do we know that anyone would be able to make the best decision?


[<== Back](https://simoneodegard.github.io/reading-notes/)